{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc72770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b9b0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def processar_video_roi(video_path, output_path):\n",
    "\n",
    "    print(\"Carregando modelo YOLOv8 Medium (mais preciso)...\")\n",
    "    model = YOLO(\"yolov8m.pt\") \n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    roi_points = np.array([\n",
    "        [618, 605], \n",
    "        [1137, 600], \n",
    "        [1417, 1047], \n",
    "        [481, 1042]\n",
    "    ], np.int32)\n",
    "    roi_points = roi_points.reshape((-1, 1, 2))\n",
    "\n",
    "    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'avc1'), fps, (width, height))\n",
    "\n",
    "    print(f\"Processando: {video_path}...\")\n",
    "    print(f\"Resolução: {width}x{height}\")\n",
    "\n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        results = model.predict(frame, conf=0.3, classes=[0], verbose=False)\n",
    "        \n",
    "        boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "        pessoas_na_roi = 0\n",
    "\n",
    "        cv2.polylines(frame, [roi_points], isClosed=True, color=(255, 0, 0), thickness=2)\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box\n",
    "            cx = int((x1 + x2) / 2)\n",
    "            cy = int(y2) \n",
    "\n",
    "            is_inside = cv2.pointPolygonTest(roi_points, (cx, cy), False)\n",
    "\n",
    "            if is_inside >= 0:\n",
    "                pessoas_na_roi += 1\n",
    "                # Caixa Verde (Dentro)\n",
    "                cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "            else:\n",
    "                # Caixa Vermelha (Fora)\n",
    "                cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 1)\n",
    "\n",
    "        # Contador visual\n",
    "        cv2.rectangle(frame, (20, 20), (350, 80), (0, 0, 0), -1)\n",
    "        cv2.putText(frame, f\"Pessoas na Area: {pessoas_na_roi}\", (35, 60), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "        out.write(frame)\n",
    "        \n",
    "        # Mostra uma versão menor na tela para não ocupar tudo se o vídeo for 4K\n",
    "        frame_small = cv2.resize(frame, (1024, int(1024 * height / width)))\n",
    "        cv2.imshow(\"Monitoramento (Preview Reduzido)\", frame_small)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Concluído! Verifique o arquivo \")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ATENÇÃO: Mudei a extensão de saída para .avi\n",
    "    processar_video_roi(\"runners.mp4\", \"resultado_roi.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8343c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from lightgbm import cv\n",
    "\n",
    "video = cv.VideoCapture(\"runners.mp4\")\n",
    "\n",
    "body_cascade = cv2.CascadeClassifier(\"haarcascade_fullbody.xml\")\n",
    "\n",
    "min_size = (30, 60) #ajustar de acordo com resolução do vídeo]\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # bodies = body_cascade.detectMultiScale(gray, 1.1, 3, minSize=min_size)\n",
    "\n",
    "    # for (x, y, w, h) in bodies:\n",
    "    #     cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # cv2.imshow(\"Video\", frame)\n",
    "    # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "    #     break\n",
    "\n",
    "frame_resized = cv2.resize(frame, dsize=(640, 480))\n",
    "\n",
    "\n",
    "gray_frame = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "gray_blurred = cv2.GaussianBlur(gray_frame, ksize=(5, 5), sigmaX=0)\n",
    "\n",
    "bodies = body_cascade.detectMultiScale(gray_blurred, scaleFactor=1.1, minNeighbors=3, minSize=min_size)\n",
    "\n",
    "for (x, y, w, h) in bodies:\n",
    "    cv2.rectangle(frame_resized, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow(winname=\"People Detection\", mat=frame_resized)\n",
    "\n",
    "if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "    break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab857e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# 1. Use cv2 directly, removed the lightgbm import\n",
    "video = cv2.VideoCapture(\"runners.mp4\")\n",
    "\n",
    "# Ensure the video opened successfully\n",
    "if not video.isOpened():\n",
    "    print(\"Error opening video file\")\n",
    "    exit()\n",
    "\n",
    "body_cascade = cv2.CascadeClassifier(\"haarcascade_fullbody.xml\")\n",
    "\n",
    "# Adjusted min_size. Since we are resizing the frame to 640x480, \n",
    "# (30, 60) is a reasonable starting point.\n",
    "min_size = (30, 60) \n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    \n",
    "    # Check if the frame was read correctly\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 2. ALL processing logic must be INSIDE the while loop\n",
    "    \n",
    "    # Resize the frame to speed up detection and standardize input\n",
    "    frame_resized = cv2.resize(frame, dsize=(640, 480))\n",
    "\n",
    "    # Convert to Grayscale\n",
    "    gray_frame = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Blur to reduce noise and false positives\n",
    "    gray_blurred = cv2.GaussianBlur(gray_frame, ksize=(5, 5), sigmaX=0)\n",
    "\n",
    "    # Detect bodies\n",
    "    # ScaleFactor 1.1 means the image is reduced by 10% at each scale\n",
    "    body_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_fullbody.xml\")\n",
    "    bodies = body_cascade.detectMultiScale(\n",
    "        gray_blurred, \n",
    "        scaleFactor=1.1, \n",
    "        minNeighbors=3, \n",
    "        minSize=min_size\n",
    "    )\n",
    "\n",
    "    # Draw rectangles\n",
    "    for (x, y, w, h) in bodies:\n",
    "        cv2.rectangle(frame_resized, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow(winname=\"People Detection\", mat=frame_resized)\n",
    "\n",
    "    # 3. Use waitKey(1) for video playback (1ms delay), not waitKey(0)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
